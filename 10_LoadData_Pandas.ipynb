{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.dataを使ってpandasのDataFrameをロードする\n",
    "\n",
    "このチュートリアルでは、pandasのDataFrameをロードして、`tf.data.Dataset`にデータを読み込む。\n",
    "\n",
    "このチュートリアルでは、クリーブランドクリニック財団(the Cleveland Clinic Foundation for Heart Disease)から提供された、小さなデータセットを使用する。\n",
    "このデータセット(CSV)には、数百行のデータが含まれている。行は各患者を、列は様々な属性を表している。\n",
    "\n",
    "このデータを使って、患者が心臓病を罹患しているかを判別予測することができる。\n",
    "なお、この問題は、二値分類問題である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandasを使ってデータを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = tf.keras.utils.get_file(\"heart.csv\", \"https://storage.googleapis.com/applied-dl/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n0   63    1   1       145   233    1        2      150      0      2.3      3   \n1   67    1   4       160   286    0        2      108      1      1.5      2   \n2   67    1   4       120   229    0        2      129      1      2.6      2   \n3   37    1   3       130   250    0        0      187      0      3.5      3   \n4   41    0   2       130   204    0        2      172      0      1.4      1   \n\n   ca        thal  target  \n0   0       fixed       0  \n1   3      normal       1  \n2   2  reversible       0  \n3   0      normal       0  \n4   0      normal       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>1</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>2</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>fixed</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>1</td>\n      <td>4</td>\n      <td>160</td>\n      <td>286</td>\n      <td>0</td>\n      <td>2</td>\n      <td>108</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>normal</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>1</td>\n      <td>4</td>\n      <td>120</td>\n      <td>229</td>\n      <td>0</td>\n      <td>2</td>\n      <td>129</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>2</td>\n      <td>2</td>\n      <td>reversible</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>1</td>\n      <td>3</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>3</td>\n      <td>0</td>\n      <td>normal</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n      <td>0</td>\n      <td>2</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>2</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>normal</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "age           int64\nsex           int64\ncp            int64\ntrestbps      int64\nchol          int64\nfbs           int64\nrestecg       int64\nthalach       int64\nexang         int64\noldpeak     float64\nslope         int64\nca            int64\nthal         object\ntarget        int64\ndtype: object"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe内で唯一の`object`型である`thal`列を離散値に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(df[\"thal\"])\n",
    "# pd.Categorical(df[\"thal\"])\n",
    "df[\"thal\"] = pd.Categorical(df[\"thal\"])\n",
    "df[\"thal\"] = df.thal.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method NDFrame.head of      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n0     63    1   1       145   233    1        2      150      0      2.3   \n1     67    1   4       160   286    0        2      108      1      1.5   \n2     67    1   4       120   229    0        2      129      1      2.6   \n3     37    1   3       130   250    0        0      187      0      3.5   \n4     41    0   2       130   204    0        2      172      0      1.4   \n..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n298   52    1   1       118   186    0        2      190      0      0.0   \n299   43    0   4       132   341    1        2      136      1      3.0   \n300   65    1   4       135   254    0        2      127      0      2.8   \n301   48    1   4       130   256    1        2      150      1      0.0   \n302   63    0   4       150   407    0        2      154      0      4.0   \n\n     slope  ca  thal  target  \n0        3   0     2       0  \n1        2   3     3       1  \n2        2   2     4       0  \n3        3   0     3       0  \n4        1   0     3       0  \n..     ...  ..   ...     ...  \n298      2   0     2       0  \n299      2   0     4       1  \n300      2   1     4       1  \n301      1   2     4       1  \n302      2   3     4       1  \n\n[303 rows x 14 columns]>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data.Datasetを使ってデータをロードする\n",
    "\n",
    "`tf.data.Dataset.from_tensor_slices`メソッドを使って、pandasのdataframeから値を読み込む。\n",
    "\n",
    "`tf.data.Dataset`を使う利点は、シンプルに使えて、かつ、大変効率的なデータパイプラインを構築できること。詳細は以下のloading data guideを参照。\n",
    "\n",
    "[loading data guide](https://www.tensorflow.org/guide/data?hl=ja)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Features: [ 63.    1.    1.  145.  233.    1.    2.  150.    0.    2.3   3.    0.\n   2. ], Target: 0\nFeatures: [ 67.    1.    4.  160.  286.    0.    2.  108.    1.    1.5   2.    3.\n   3. ], Target: 1\nFeatures: [ 67.    1.    4.  120.  229.    0.    2.  129.    1.    2.6   2.    2.\n   4. ], Target: 0\nFeatures: [ 37.    1.    3.  130.  250.    0.    0.  187.    0.    3.5   3.    0.\n   3. ], Target: 0\nFeatures: [ 41.    0.    2.  130.  204.    0.    2.  172.    0.    1.4   1.    0.\n   3. ], Target: 0\n"
    }
   ],
   "source": [
    "target = df.pop(\"target\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))\n",
    "\n",
    "for feat, targ in dataset.take(5):\n",
    "    print(\"Features: {}, Target: {}\".format(feat, targ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.Series`は`__array__`プロトコルを実装しているため、`np.array`や`tf.Tensor`を使うところでは、だいたいどこでも使うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(303,), dtype=int32, numpy=\narray([2, 3, 4, 3, 3, 3, 3, 3, 4, 4, 2, 3, 2, 4, 4, 3, 4, 3, 3, 3, 3, 3,\n       3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 3, 4, 2, 4, 3, 4, 3, 4, 4,\n       2, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4,\n       4, 2, 3, 3, 4, 3, 4, 3, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 4, 4, 4,\n       3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 3, 3, 4, 4, 4, 4, 4,\n       3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 2, 4, 4, 2, 3, 3, 4, 4, 3, 4,\n       3, 3, 4, 2, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n       4, 3, 3, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3,\n       3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 2,\n       4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 2, 2, 4, 3, 4, 2, 4, 3,\n       3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 2, 2, 4, 3, 4, 3, 2, 4, 3, 3, 2,\n       4, 4, 4, 4, 3, 0, 3, 3, 3, 3, 1, 4, 3, 3, 3, 4, 3, 4, 3, 3, 3, 4,\n       3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3, 3,\n       3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 3, 2, 4, 4, 4, 4])>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "tf.constant(df[\"thal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データをシャッフルしてバッチ処理を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(len(df)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを作成して訓練する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 303 steps\nEpoch 1/15\n303/303 [==============================] - 1s 4ms/step - loss: 0.9406 - accuracy: 0.7063\nEpoch 2/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.6647 - accuracy: 0.7327\nEpoch 3/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.6030 - accuracy: 0.7393\nEpoch 4/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.5611 - accuracy: 0.7459\nEpoch 5/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7525\nEpoch 6/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.5533 - accuracy: 0.7591\nEpoch 7/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7228\nEpoch 8/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7261\nEpoch 9/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7756\nEpoch 10/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.5608 - accuracy: 0.7459\nEpoch 11/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.4980 - accuracy: 0.7756\nEpoch 12/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.4727 - accuracy: 0.7723\nEpoch 13/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8020\nEpoch 14/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.7723\nEpoch 15/15\n303/303 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7855\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x157d644fa08>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴列の代替\n",
    "\n",
    "モデルへの入力に辞書型データを渡すことは、`tf.keras.layers.Input`に同じ型の辞書を作成し、何らかの前処理を適用して`functional api`を使ってスタッキングすることと同様に、簡単に行うことができる。\n",
    "これを特徴列(feature columns)の替わりに使うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {key: tf.keras.layers.Input(shape=(), name=key) for key in df.keys()}\n",
    "x = tf.stack(list(inputs.values()), axis=-1)\n",
    "\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_func = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model_func.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.data`を使う時に、pandas の DataFrame の列構造を保持する一番簡単な方法は、DataFrame を辞書型データに変換して、先頭を切り取ることpandas の DataFrame の列構造を保持する一番簡単な方法は、DataFrame を辞書型データに変換して、先頭を切り取ること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "({'age': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([63, 67, 67, 37, 41, 56, 62, 57, 63, 53, 57, 56, 56, 44, 52, 57])>, 'sex': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1])>, 'cp': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3, 2, 3, 3])>, 'trestbps': <tf.Tensor: shape=(16,), dtype=int32, numpy=\narray([145, 160, 120, 130, 130, 120, 140, 120, 130, 140, 140, 140, 130,\n       120, 172, 150])>, 'chol': <tf.Tensor: shape=(16,), dtype=int32, numpy=\narray([233, 286, 229, 250, 204, 236, 268, 354, 254, 203, 192, 294, 256,\n       263, 199, 168])>, 'fbs': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0])>, 'restecg': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0])>, 'thalach': <tf.Tensor: shape=(16,), dtype=int32, numpy=\narray([150, 108, 129, 187, 172, 178, 160, 163, 147, 155, 148, 153, 142,\n       173, 162, 174])>, 'exang': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0])>, 'oldpeak': <tf.Tensor: shape=(16,), dtype=float32, numpy=\narray([2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6, 1.4, 3.1, 0.4, 1.3, 0.6,\n       0. , 0.5, 1.6], dtype=float32)>, 'slope': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2, 1, 1, 1])>, 'ca': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([0, 3, 2, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0])>, 'thal': <tf.Tensor: shape=(16,), dtype=int32, numpy=array([2, 3, 4, 3, 3, 3, 3, 3, 4, 4, 2, 3, 2, 4, 4, 3])>}, <tf.Tensor: shape=(16,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)>)\n"
    }
   ],
   "source": [
    "dict_slices = tf.data.Dataset.from_tensor_slices((df.to_dict('list'), target.values)).batch(16)\n",
    "for dict_slice in dict_slices.take(1):\n",
    "  print (dict_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 19 steps\nEpoch 1/15\n19/19 [==============================] - 0s 20ms/step - loss: 52.8702 - accuracy: 0.2739\nEpoch 2/15\n19/19 [==============================] - 0s 3ms/step - loss: 35.8708 - accuracy: 0.2739\nEpoch 3/15\n19/19 [==============================] - 0s 3ms/step - loss: 17.0307 - accuracy: 0.2739\nEpoch 4/15\n19/19 [==============================] - 0s 3ms/step - loss: 2.5448 - accuracy: 0.5974\nEpoch 5/15\n19/19 [==============================] - 0s 3ms/step - loss: 1.6373 - accuracy: 0.7459\nEpoch 6/15\n19/19 [==============================] - 0s 3ms/step - loss: 1.1861 - accuracy: 0.6832\nEpoch 7/15\n19/19 [==============================] - 0s 4ms/step - loss: 1.0891 - accuracy: 0.7030\nEpoch 8/15\n19/19 [==============================] - 0s 4ms/step - loss: 0.9973 - accuracy: 0.7063\nEpoch 9/15\n19/19 [==============================] - 0s 3ms/step - loss: 0.9375 - accuracy: 0.6997\nEpoch 10/15\n19/19 [==============================] - 0s 3ms/step - loss: 0.8633 - accuracy: 0.7162\nEpoch 11/15\n19/19 [==============================] - 0s 3ms/step - loss: 0.8048 - accuracy: 0.7162\nEpoch 12/15\n19/19 [==============================] - 0s 4ms/step - loss: 0.7501 - accuracy: 0.7228\nEpoch 13/15\n19/19 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.7294\nEpoch 14/15\n19/19 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.7261\nEpoch 15/15\n19/19 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.7261\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1595a59f2c8>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model_func.fit(dict_slices, epochs=15)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594363575223",
   "display_name": "Python 3.7.7 64-bit ('tensorflow2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}