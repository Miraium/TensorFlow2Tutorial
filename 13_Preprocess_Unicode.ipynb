{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595470993858",
   "display_name": "Python 3.7.7 64-bit ('tensorflow2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode文字列\n",
    "\n",
    "## はじめに\n",
    "\n",
    "自然言語モデルは、しばしば異なる文字セットを使った異なる言語を扱う。\n",
    "Unicodeは、ほぼすべての言語れ文字表示に使われている標準的なエンコードの仕組み。各文字は、`0`から`0x10FFFF`までの一意の整数の\n",
    "[コードポイント(符号点))](https://ja.wikipedia.org/wiki/%E7%AC%A6%E5%8F%B7%E7%82%B9)\n",
    "を使ってエンコードされる。1つのUnicode文字列は、ゼロ個以上のコードポイントのシーケンスになっている。\n",
    "\n",
    "このチュートリアルでは、TensorFlowでのUnicode文字列の表現方法と、どうやってUnicodeで標準的な文字列操作と同様の操作を行うかについて示す。\n",
    "また、スクリプト検出に基づいてUnicode文字列をトークンに分解する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.stringデータ型\n",
    "\n",
    "標準的なTensorFlowの`tf.string`型は、バイト列のテンソルを作る。また、Unicode文字列はデフォルトではutf-8でエンコードされる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "tf.constant(u\"Thanks 😊\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バイト列が最小限の単位として扱われるため、`tf.string`型のテンソルは可変長のバイト列を保持できる。\n",
    "また、文字列長はテンソルの次元には含まれない。\n",
    "\n",
    "注：Pythonを使って文字列を構成する時、v2.x系とv3.x系ではUnicodeの扱いが異なる。\n",
    "v2.x系では、Unicode文字列は上記のようにプレフィックス\"u\"で明示する。\n",
    "v3.x系では、デフォルトでUnicodeとしてエンコードされる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TensorShape([2])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tf.constant([u\"You're]\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode表現\n",
    "\n",
    "TensorFlowでのUnicode文字列表現は、2つの標準的な方法がある：\n",
    "\n",
    "- `string`スカラー - コードポイントのシーケンスは既知の文字列符号化方式でエンコードされる。\n",
    "- `int32`ベクトル - 各文字には単一のコードポイントが入る。\n",
    "\n",
    "例えば、以下3つはすべてUnicode文字列`语言処理`(中国語で「言語処理」を意味する)を表す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\x87\\xa6\\xe7\\x90\\x86'>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Unicode文字列。UTF-8にエンコードされた文字列スカラーとして表される。\n",
    "text_utf8 = tf.constant(u\"语言処理\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Q\\xe6t\\x06'>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Unicode文字列。UTF-16-BEにエンコードされた文字列スカラーとして表される。\n",
    "text_utf16 = tf.constant(u\"语言処理\".encode(\"UTF-16-BE\"))\n",
    "text_utf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 20966, 29702])>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Unicode文字列。Unicodeコードポイントのベクトルとして表される。\n",
    "text_chars = tf.constant([ord(char) for char in u\"语言処理\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unicode表現間の変換\n",
    "\n",
    "TensorFlowでは、これらの異なるUnicode表現間で変換する方法を用意している。\n",
    "\n",
    "- `tf.strings.unicode_decode`: エンコードされた文字列スカラーを、コードポイントのベクトルに変換する。\n",
    "- `tf.strings.unicode_encode`: コードポイントのベクトルを、エンコードされた文字列スカラーに変換する。\n",
    "- `tf.strings.unicode_transcode`: エンコードされた文字列スカラーを、別の文字コードに再エンコードする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 20966, 29702])>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "tf.strings.unicode_decode(text_utf8, input_encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\x87\\xa6\\xe7\\x90\\x86'>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "tf.strings.unicode_encode(text_chars, output_encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Q\\xe6t\\x06'>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf8, input_encoding=\"UTF-8\", output_encoding=\"UTF-16-BE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチの次元\n",
    "\n",
    "複数の文字列をデコードする場合、各文字列の文字数が等しくない場合がある。\n",
    "返される結果は`tf.RaggedTensor`であり、最も内側の次元の長さは各文字列の文字数によって異なる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[104, 195, 108, 108, 111]\n[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n[71, 246, 246, 100, 110, 105, 103, 104, 116]\n[128522]\n"
    }
   ],
   "source": [
    "# Unicode文字列のバッチ。それぞれが、UTF8にエンコードされた文字列として表される\n",
    "batch_utf8 = [s.encode('UTF-8') for s in\n",
    "              [u'hÃllo',  u'What is the weather tomorrow',  u'Göödnight', u'😊']]\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
    "                                               input_encoding='UTF-8')\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "  print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータの処理方法には3つの選択肢がある。\n",
    "\n",
    "1. この`tf.RaggedTensor`を直接使用する\n",
    "2. `tf.RaggedTensor.to_tensor`メソッドを使ってパディングを追加した密な`tf.Tensor`に変換する\n",
    "3. `tf.RaggedTensor.to_sparse`メソッドを使って`tf.SparseTensor`に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(\n[[   104    195    108    108    111     -1     -1     -1     -1     -1\n      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n      -1     -1     -1     -1     -1     -1     -1     -1]\n [    87    104     97    116     32    105    115     32    116    104\n     101     32    119    101     97    116    104    101    114     32\n     116    111    109    111    114    114    111    119]\n [    71    246    246    100    110    105    103    104    116     -1\n      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n      -1     -1     -1     -1     -1     -1     -1     -1]\n [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n      -1     -1     -1     -1     -1     -1     -1     -1]], shape=(4, 28), dtype=int32)\n"
    }
   ],
   "source": [
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SparseTensor(indices=tf.Tensor(\n[[ 0  0]\n [ 0  1]\n [ 0  2]\n [ 0  3]\n [ 0  4]\n [ 1  0]\n [ 1  1]\n [ 1  2]\n [ 1  3]\n [ 1  4]\n [ 1  5]\n [ 1  6]\n [ 1  7]\n [ 1  8]\n [ 1  9]\n [ 1 10]\n [ 1 11]\n [ 1 12]\n [ 1 13]\n [ 1 14]\n [ 1 15]\n [ 1 16]\n [ 1 17]\n [ 1 18]\n [ 1 19]\n [ 1 20]\n [ 1 21]\n [ 1 22]\n [ 1 23]\n [ 1 24]\n [ 1 25]\n [ 1 26]\n [ 1 27]\n [ 2  0]\n [ 2  1]\n [ 2  2]\n [ 2  3]\n [ 2  4]\n [ 2  5]\n [ 2  6]\n [ 2  7]\n [ 2  8]\n [ 3  0]], shape=(43, 2), dtype=int64), values=tf.Tensor(\n[   104    195    108    108    111     87    104     97    116     32\n    105    115     32    116    104    101     32    119    101     97\n    116    104    101    114     32    116    111    109    111    114\n    114    111    119     71    246    246    100    110    105    103\n    104    116 128522], shape=(43,), dtype=int32), dense_shape=tf.Tensor([ 4 28], shape=(2,), dtype=int64))\n"
    }
   ],
   "source": [
    "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
    "print(batch_chars_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じ長さの複数の文字列をエンコードする場合、`tf.Tensor`を入力値として使用できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [99, 111, 119]], output_encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可変長の複数の文字列をエンコードする場合、`tf.RaggedTensor`を入力値として使用する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=string, numpy=\narray([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# batch_chars_raggedはtf.RaggedTensor\n",
    "print(type(batch_chars_ragged))\n",
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パディングされた、あるいはスパースな複数の文字列を含むテンソルがある場合は、`unicode_encode`を呼び出す前に`tf.RaggedTensor`に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=string, numpy=\narray([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_sparse(batch_chars_sparse), output_encoding=\"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=string, numpy=\narray([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1), output_encoding=\"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode操作\n",
    "\n",
    "### 文字列長\n",
    "\n",
    "`tf.strings.length`には、文字列長をどう計算するか示す`unit`パラメーターが使える。\n",
    "`unit`のデフォルトは`\"BYTE\"`だが、`\"UTF-8_CHAR\"`や`\"UTF-16_CHAR\"`などの他の値に設定して、エンコードされた`string`文字列のUnicodeコードポイントの数を決めることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "11 bytes; 8 UTF-8 characters\n"
    }
   ],
   "source": [
    "# 最後の絵文字は、UTF8で4バイトを占めることに注意する。\n",
    "thanks = u\"Thanks 😊\".encode(\"UTF-8\")\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit=\"UTF8_CHAR\").numpy()\n",
    "print(\"{} bytes; {} UTF-8 characters\".format(num_bytes, num_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部分文字列\n",
    "\n",
    "同様に、`tf.strings.substr`では、`unit`パラメータを使い、かつ`pos`および`len`パラメーターを指定することで、オフセットの種類を決めることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'\\xf0'"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# デフォルト：unit=\"BYTE\". len=1 の場合、1バイトを返す\n",
    "tf.strings.substr(thanks, pos=7, len=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(), dtype=string, numpy=b'\\xf0\\x9f\\x98\\x8a'>>\n"
    }
   ],
   "source": [
    "# unit = \"UTF8_CHAR\"を指定すると、単一の文字（この場合は4バイト）が返される\n",
    "print(tf.strings.substr(thanks, pos=7, len=1, unit=\"UTF8_CHAR\").numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unicode部文字列を分割する\n",
    "\n",
    "`tf.strings.unicode_split`は、Unicode文字列を個々の文字に分割する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, \"UTF-8\").numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文字のバイトオフセット\n",
    "\n",
    "`tf.strings.unicode_decode`によって生成された文字テンソルを元の文字列に戻すには、各文字の開始位置のオフセットを知ることが役立つ。\n",
    "\n",
    "`tf.strings.unicode_decode_with_offset`メソッドは`unicode_decode`に似ているが、各文字の開始オフセットを含む2番目のテンソルを返す点が異なる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "At byte offset 0: codepoint 127880\nAt byte offset 4: codepoint 127881\nAt byte offset 8: codepoint 127882\n"
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"🎈🎉🎊\", 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "  print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicodeスクリプト\n",
    "\n",
    "各Unicodeコードポイントは、スクリプトとして知られる単一のコードポイント集合に属している。\n",
    "文字スクリプトは、その文字がどの言語なのかを判断するのに役立つ。\n",
    "例えば、「Б」がキリル文字であることがわかれば、その文字を含むテキストはロシア語やウクライナ語などのスラブ言語である可能性が高いことがわかる。\n",
    "\n",
    "TensorFlowは、あるコードポイントがどのスクリプトかを返す`tf.strings.unicode_script`を提供している。\n",
    "戻り値のスクリプトコードは、International Components for Unicode (ICU)の`UScriptCode`に対応する`int32`値になる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[17  8]\n"
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['芸', 'Б']\n",
    "\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.strings.unicode_script`は、多次元のコードポイントの`tf.Tensor`や`tf.RaddedTensor`にも適用できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
    }
   ],
   "source": [
    "print(tf.strings.unicode_script(batch_chars_ragged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例：シンプルなセグメンテーション\n",
    "\n",
    "セグメンテーションは、テキストを単語のような粒度に分割するタスク。\n",
    "これは、スペース文字を使用して単語を区切れる場合には簡単に行えるが、一部の言語（中国語や日本語など）はスペースを使わないし、\n",
    "また、一部の言語（ドイツ語など）には、意味を解析するため分ける必要がある、単語を結合した長い複合語がある。\n",
    "Webテキストでは「NY株価」（ニューヨーク株価）のように、異なる言語とスクリプトがしばしば混在している。\n",
    "\n",
    "単語の境界を推定してスクリプトを変更することにより、（MLモデルを実装せずに）非常に大まかなセグメンテーションを実行できる。\n",
    "これは、上記の「NY株価」の例のような文字列に対して機能する。\n",
    "様々な言語のスペース文字はすべて、実際のテキストとは異なる特別なスクリプトコードであるUSCRIPT_COMMONとして分類されるため、スペースを使用するほとんどの言語で機能する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype: string; shape: [num_sentences]\n",
    "# 処理する文章。この行を編集して、さまざまな入力を試してみること\n",
    "sentence_texts = [u'Hello, world.', u'世界こんにちは']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初に、文章を文字ごとのコードポイントにデコードし、それから各文字のスクリプトコード（識別子）を調べる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_codepoint[i, j] は、i番目の文のj番目の文字のコードポイント\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_scripts[i, j] は、i番目の文のj番目の文字のスクリプトコード\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、これらのスクリプトコードを使って、単語の境界を追加すべき場所を決める。\n",
    "前の文字とスクリプトコードが異なるそれぞれの文字の先頭に、単語の境界を追加する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.RaggedTensor [[True, False, False, False, False, True, False, True, False, False, False, False, True], [True, False, True, False, False, False, False]]>\ntf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
    }
   ],
   "source": [
    "# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_starts_word[i, j] は、i番目の文のj番目の文字が単語の始まりである場合にTrue\n",
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([sentence_char_script.nrows(), 1], True), #1文字目は必ずTrue\n",
    "     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])], # スクリプトが異なるかどうか比較 第一引数は1index始まり 第二引数は0index始まりにすることで、1文字前との比較を実現\n",
    "    axis=1)\n",
    "print(sentence_char_starts_word)\n",
    "\n",
    "# dtype: int64; shape: [num_words]\n",
    "#\n",
    "# word_starts[i] は、i番目の単語の始まりである文字のインデックス\n",
    "# （すべての文がフラット化された文字リスト）\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして、これらの目印（開始オフセット）を使って、各単語ごとの文字リストを含む`RaggedTensor`を作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
    "#\n",
    "# word_char_codepoint[i, j] は、i番目の単語のj番目の文字のコードポイント\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
    "    values=sentence_char_codepoint.values,\n",
    "    row_starts=word_starts)\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、`RaggedTensor`をコードポイント単位でセグメント化して、文章に戻す。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor([4 2], shape=(2,), dtype=int64)\n<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_sentences]\n",
    "#\n",
    "# sentence_num_words[i] は、i番目の文の単語数\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "# 'Hello, world.'は4単語分割、'世界こんにちは'は2単語分割できる、という結果が返ってくる。\n",
    "print(sentence_num_words)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "#\n",
    "# sentence_word_char_codepoint[i, j, k] は、i番目の文のj番目の単語のk番目の文字のコードポイント\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "print(word_char_codepoint) # Before\n",
    "print(sentence_word_char_codepoint) # After"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最終的な結果を見やすくするために、UTF-8文字列にエンコードする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[b'Hello', b', ', b'world', b'.'],\n [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "tf.strings.unicode_encode(sentence_word_char_codepoint, \"UTF-8\").to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}